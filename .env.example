# Cyber-AutoAgent Environment Configuration Template
# Copy this file to .env and customize for your environment

# RECOMMENDATION: keep the .env file lean by focusing on AWS_* access credentials and
# potentially remote stores (if you use them) and otherwise rely on the agent default values
# or modify them via the config.py

# ==============================================================================
# MODEL PROVIDER CONFIGURATION
# ==============================================================================

# Choose your model provider: 'bedrock' (AWS Bedrock), 'ollama' (Local), or 'litellm' (Universal)
# Default: bedrock
# CYBER_AGENT_PROVIDER=bedrock

# ==============================================================================
# AWS BEDROCK CONFIGURATION (Direct or via LiteLLM)
# ==============================================================================

# AWS Credentials for Bedrock access
# Required for bedrock provider - use either standard credentials OR bearer token
# Option 1: Standard AWS credentials
# AWS_ACCESS_KEY_ID=your_aws_access_key
# AWS_SECRET_ACCESS_KEY=your_aws_secret_key

# Option 2: AWS Bedrock API key (bearer token)
AWS_BEARER_TOKEN_BEDROCK=your_bearer_token

AWS_REGION=us-east-1

# Override default LLM model
# Default: us.anthropic.claude-sonnet-4-20250514-v1:0
# CYBER_AGENT_LLM_MODEL=us.anthropic.claude-3-5-sonnet-20241022-v2:0

# Override default embedding model
# Default: amazon.titan-embed-text-v2:0
# CYBER_AGENT_EMBEDDING_MODEL=amazon.titan-embed-text-v2:0

# Override evaluation model
# Default: us.anthropic.claude-3-5-sonnet-20241022-v2:0
# CYBER_AGENT_EVALUATION_MODEL=us.anthropic.claude-3-5-sonnet-20241022-v2:0
# RAGAS_EVALUATOR_MODEL=us.anthropic.claude-3-5-sonnet-20241022-v2:0

# Override swarm model
# Default: us.anthropic.claude-3-5-sonnet-20241022-v2:0
# CYBER_AGENT_SWARM_MODEL=us.anthropic.claude-3-5-sonnet-20241022-v2:0

# ==============================================================================
# LITELLM CONFIGURATION (Universal Provider)
# ==============================================================================

# LiteLLM supports 100+ model providers via unified interface
# Model format: provider/model-name (e.g., bedrock/claude, openai/gpt-4, anthropic/claude)

# For Bedrock models via LiteLLM (uses AWS credentials above)
# CYBER_AGENT_LLM_MODEL=bedrock/us.anthropic.claude-sonnet-4-20250514-v1:0

# For OpenAI models via LiteLLM
# OPENAI_API_KEY=your_openai_api_key
# CYBER_AGENT_LLM_MODEL=openai/gpt-4o

# For Anthropic models via LiteLLM
# ANTHROPIC_API_KEY=your_anthropic_api_key
# CYBER_AGENT_LLM_MODEL=anthropic/claude-3-7-sonnet-20250219

# For Cohere models via LiteLLM
# COHERE_API_KEY=your_cohere_api_key
# CYBER_AGENT_LLM_MODEL=cohere/command-r-plus

# ==============================================================================
# OLLAMA CONFIGURATION (Local Provider)
# ==============================================================================

# Ollama server host
# Default: auto-detected (localhost or host.docker.internal)
# OLLAMA_HOST=http://localhost:11434

# Override default LLM model for local mode
# Default: llama3.2:3b
# CYBER_AGENT_LLM_MODEL=llama3.2:3b

# Override default embedding model for local mode
# Default: mxbai-embed-large
# CYBER_AGENT_EMBEDDING_MODEL=mxbai-embed-large

# ==============================================================================
# MEMORY SYSTEM CONFIGURATION
# ==============================================================================

# Memory backend provider configuration
# Options: FAISS (default), OpenSearch, Mem0 Platform

# Mem0 Platform (cloud-based memory)
# Get your API key from https://mem0.ai
# MEM0_API_KEY=your_mem0_api_key

# OpenSearch backend
# OPENSEARCH_HOST=https://your-opensearch-domain.region.es.amazonaws.com

# Override memory LLM model
# MEM0_LLM_MODEL=llama3.2:3b

# Override memory embedding model
# MEM0_EMBEDDING_MODEL=mxbai-embed-large

# ==============================================================================
# OUTPUT DIRECTORY CONFIGURATION
# ==============================================================================

# Base directory for all output artifacts
# Default: ./outputs (relative to project root)
# CYBER_AGENT_OUTPUT_DIR=/custom/outputs

# Enable unified output directory structure
# Default: true (recommended)
# CYBER_AGENT_ENABLE_UNIFIED_OUTPUT=true

# ==============================================================================
# OBSERVABILITY & MONITORING
# ==============================================================================

# Enable/disable observability tracing
# Default: true
# ENABLE_OBSERVABILITY=true

# Langfuse configuration for observability
LANGFUSE_HOST=http://localhost:3000
LANGFUSE_PUBLIC_KEY=cyber-public
LANGFUSE_SECRET_KEY=cyber-secret

# Langfuse security settings (for production)
# LANGFUSE_ENCRYPTION_KEY=your-32-char-hex-key
# LANGFUSE_SALT=your-16-char-hex-salt
# LANGFUSE_ADMIN_PASSWORD=your-strong-password

# Enable debug trace output to console
# Default: false
# DEBUG_TRACES=true

# ==============================================================================
# PROMPT MANAGEMENT (LANGFUSE)
# ==============================================================================

# Enable Langfuse prompt management for dynamic prompt updates
# Default: false (uses hardcoded prompts)
# ENABLE_LANGFUSE_PROMPTS=true

# Langfuse prompt label to use (production, staging, dev)
# Default: production
# LANGFUSE_PROMPT_LABEL=production

# Cache TTL for prompts in seconds
# Default: 300 (5 minutes)
# LANGFUSE_PROMPT_CACHE_TTL=300

# ==============================================================================
# EVALUATION SYSTEM
# ==============================================================================

# Enable automatic evaluation after operations
# Default: false
# ENABLE_AUTO_EVALUATION=true

# ==============================================================================
# DEVELOPMENT & DEBUGGING
# ==============================================================================

# Development mode
# Default: false
# DEV=true

# Bypass tool consent prompts
# Default: false (prompts enabled)
# BYPASS_TOOL_CONSENT=true

# ==============================================================================
# EXAMPLE CONFIGURATIONS
# ==============================================================================

# Example 1: Local development with Ollama
# CYBER_AGENT_SERVER=local
# OLLAMA_HOST=http://localhost:11434
# CYBER_AGENT_OUTPUT_DIR=./outputs
# ENABLE_OBSERVABILITY=true
# LANGFUSE_HOST=http://localhost:3000

# Example 2: Remote production with AWS Bedrock
# CYBER_AGENT_SERVER=remote
# AWS_ACCESS_KEY_ID=your_key
# AWS_SECRET_ACCESS_KEY=your_secret
# AWS_REGION=us-east-1
# CYBER_AGENT_OUTPUT_DIR=/app/outputs
# ENABLE_AUTO_EVALUATION=true
# MEM0_API_KEY=your_mem0_key

# Example 3: Container deployment with unified output
# CYBER_AGENT_ENABLE_UNIFIED_OUTPUT=true
# CYBER_AGENT_OUTPUT_DIR=/app/outputs
# ENABLE_OBSERVABILITY=true
# LANGFUSE_HOST=http://langfuse-web:3000